{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_colab.ipynb のコピー",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2cAeBjuFHF7FUFAA7lkHM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Futaba-Kosuke/STL10/blob/develop/training/main_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KRaBgYNVutS",
        "colab_type": "code",
        "outputId": "7ecdaa6b-e498-4294-884e-af5519256e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trVgPakJWEdB",
        "colab_type": "code",
        "outputId": "9e390617-07ef-49c2-a56e-d504f73b2db2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        " !ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  images  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGHNmQCpfwZT",
        "colab_type": "code",
        "outputId": "6f8bc31e-78ad-4373-ee77-551e6df8c996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# バージョン確認 (Google Colab default)\n",
        "print(torch.__version__)  # 1.4.0\n",
        "print(torchvision.__version__)  # 0.5.0\n",
        "print(np.__version__)  # 1.18.2\n",
        "print(matplotlib.__version__)  # 3.2.1\n",
        "print(Image.__version__)  # 7.0.0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n",
            "0.5.0\n",
            "1.18.2\n",
            "3.2.1\n",
            "7.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2s-Jtq3XQD1",
        "colab_type": "code",
        "outputId": "fdc3ac8c-66d5-4617-a2f4-9efb891829d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyv8j1EsbY2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 25\n",
        "num_workers = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjHJA6g3_oS5",
        "colab_type": "code",
        "outputId": "72120089-9d92-426b-d00f-5d612edb4337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# データの読み込み\n",
        "transform = {\n",
        "  'train': transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(p=0.5),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "  ),\n",
        "  'test': transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "  )\n",
        "}\n",
        "data_set = {\n",
        "  x: torchvision.datasets.STL10(root='./images', split=x, download=True, transform=transform[x])\n",
        "  for x in ('train', 'test')\n",
        "}\n",
        "data_size = {\n",
        "  x: len(data_set[x]) for x in ('train', 'test')\n",
        "}\n",
        "print(data_size)\n",
        "\n",
        "data_loaders = {\n",
        "  x[0]: torch.utils.data.DataLoader(data_set[x[0]], batch_size=x[1], shuffle=x[2], num_workers=num_workers)\n",
        "  for x in (('train', batch_size, True), ('test', 100, False))\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "{'train': 5000, 'test': 8000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLid3_CJ_t20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('airplane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1GPSyQ2_y4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e72e213d-b024-4db6-ac18-b0010bf970a5"
      },
      "source": [
        "\"\"\"\n",
        "各モデルで10エポック学習して検証\n",
        "resnet: 90 %\n",
        "alexnet: 79 %\n",
        "vgg16: 93 %\n",
        "densenet: 94 %\n",
        "googlenet: 90 %\n",
        "shufflenet: 62 %\n",
        "mobilenet: 89 %\n",
        "resnext: 93 %\n",
        "wide_resnet: 94 %\n",
        "mnasnet: 85 %\n",
        "\n",
        "vgg16, densenet, wide_resnetを一旦採用、各々学習させてモデルを出力させた。\n",
        "\"\"\"\n",
        "\n",
        "# モデル構築\n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "\n",
        "# net = models.vgg16(pretrained=True)\n",
        "# last_in_features = net.classifier[6].in_features\n",
        "# net.classifier[6] = nn.Linear(last_in_features, 10)\n",
        "\n",
        "# net = models.densenet161(pretrained=True)\n",
        "# last_in_features = net.classifier.in_features\n",
        "# net.classifier = nn.Linear(last_in_features, 10)\n",
        "\n",
        "net = models.wide_resnet50_2(pretrained=True)\n",
        "last_in_features = net.fc.in_features\n",
        "net.fc = nn.Linear(last_in_features, 10)\n",
        "\n",
        "net = net.to(device)\n",
        "net"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CksYNuzb_3zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 損失・最適関数の定義\n",
        "from torch import optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # 10エポックごとに学習率が1/10に更新"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXlZxAgn_-Xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 学習用関数\n",
        "def train_net(net, criterion, optimizer, scheduler, num_epochs):\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch %d/%d' % (epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    running_loss_sum = 0\n",
        "    train_loss_sum = 0\n",
        "    test_loss_sum = 0\n",
        "\n",
        "    # モデルの更新\n",
        "    net.train()\n",
        "    for i, (inputs, labels) in enumerate(data_loaders['train']):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      # 勾配の初期化\n",
        "      optimizer.zero_grad()\n",
        "      # 予測\n",
        "      outputs = net(inputs)\n",
        "      # 損失の導出\n",
        "      loss = criterion(outputs, labels)\n",
        "      # 逆伝播\n",
        "      loss.backward()\n",
        "      # 勾配の更新\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss_sum += loss.item()\n",
        "      train_loss_sum += loss.item()\n",
        "      if i % 50 == 49:\n",
        "        print('[%d] running_loss: %.6f' % (i + 1, running_loss_sum / 50))\n",
        "        running_loss_sum = 0\n",
        "\n",
        "    train_cnt = i\n",
        "\n",
        "    # モデルの評価\n",
        "    net.eval()\n",
        "    cnt_correct = 0\n",
        "    for i, (inputs, labels) in enumerate(data_loaders['test']):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # 予測\n",
        "      outputs = net(inputs)\n",
        "      # 損失の導出\n",
        "      loss = criterion(outputs, labels)\n",
        "      # lossの加算\n",
        "      test_loss_sum += loss.item()\n",
        "\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      is_correct = (predicted == labels).squeeze()\n",
        "      \n",
        "      for j in range(len(is_correct)):\n",
        "        cnt_correct += is_correct[j].item()  # 正解なら1, 不正解なら0\n",
        "\n",
        "    test_cnt = i\n",
        "\n",
        "    print('')\n",
        "    print('train_loss_ave:\\t%.6f' % (train_loss_sum / train_cnt))\n",
        "    print('test_loss_ave:\\t%.6f' % (test_loss_sum / test_cnt))\n",
        "    print('test_accuracy: \\t%.6f %%' % (cnt_correct / (test_cnt)))\n",
        "\n",
        "    net.train()\n",
        "    scheduler.step()\n",
        "\n",
        "    if cnt_correct / (test_cnt) > 96:\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyFeUot5AE-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c843ee2-5cd8-4b43-f64b-6d272077e576"
      },
      "source": [
        "num_epochs = 100\n",
        "train_net(net, criterion, optimizer, scheduler, num_epochs)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/99\n",
            "----------\n",
            "[50] running_loss: 1.798012\n",
            "[100] running_loss: 0.839991\n",
            "[150] running_loss: 0.603944\n",
            "[200] running_loss: 0.537368\n",
            "\n",
            "train_loss_ave:\t0.949577\n",
            "test_loss_ave:\t0.278594\n",
            "test_accuracy: \t92.417722 %\n",
            "Epoch 1/99\n",
            "----------\n",
            "[50] running_loss: 0.447262\n",
            "[100] running_loss: 0.375123\n",
            "[150] running_loss: 0.299524\n",
            "[200] running_loss: 0.334651\n",
            "\n",
            "train_loss_ave:\t0.365970\n",
            "test_loss_ave:\t0.229476\n",
            "test_accuracy: \t93.569620 %\n",
            "Epoch 2/99\n",
            "----------\n",
            "[50] running_loss: 0.240076\n",
            "[100] running_loss: 0.288222\n",
            "[150] running_loss: 0.281907\n",
            "[200] running_loss: 0.253488\n",
            "\n",
            "train_loss_ave:\t0.267259\n",
            "test_loss_ave:\t0.207230\n",
            "test_accuracy: \t94.506329 %\n",
            "Epoch 3/99\n",
            "----------\n",
            "[50] running_loss: 0.235370\n",
            "[100] running_loss: 0.182753\n",
            "[150] running_loss: 0.186859\n",
            "[200] running_loss: 0.179202\n",
            "\n",
            "train_loss_ave:\t0.197031\n",
            "test_loss_ave:\t0.182940\n",
            "test_accuracy: \t95.379747 %\n",
            "Epoch 4/99\n",
            "----------\n",
            "[50] running_loss: 0.184082\n",
            "[100] running_loss: 0.178825\n",
            "[150] running_loss: 0.166645\n",
            "[200] running_loss: 0.161811\n",
            "\n",
            "train_loss_ave:\t0.173709\n",
            "test_loss_ave:\t0.189514\n",
            "test_accuracy: \t95.189873 %\n",
            "Epoch 5/99\n",
            "----------\n",
            "[50] running_loss: 0.146569\n",
            "[100] running_loss: 0.129044\n",
            "[150] running_loss: 0.133156\n",
            "[200] running_loss: 0.128152\n",
            "\n",
            "train_loss_ave:\t0.134905\n",
            "test_loss_ave:\t0.197603\n",
            "test_accuracy: \t95.265823 %\n",
            "Epoch 6/99\n",
            "----------\n",
            "[50] running_loss: 0.110831\n",
            "[100] running_loss: 0.115026\n",
            "[150] running_loss: 0.119188\n",
            "[200] running_loss: 0.097515\n",
            "\n",
            "train_loss_ave:\t0.111196\n",
            "test_loss_ave:\t0.176140\n",
            "test_accuracy: \t95.734177 %\n",
            "Epoch 7/99\n",
            "----------\n",
            "[50] running_loss: 0.094946\n",
            "[100] running_loss: 0.105081\n",
            "[150] running_loss: 0.110740\n",
            "[200] running_loss: 0.099784\n",
            "\n",
            "train_loss_ave:\t0.103154\n",
            "test_loss_ave:\t0.178846\n",
            "test_accuracy: \t95.531646 %\n",
            "Epoch 8/99\n",
            "----------\n",
            "[50] running_loss: 0.105412\n",
            "[100] running_loss: 0.096437\n",
            "[150] running_loss: 0.091596\n",
            "[200] running_loss: 0.108853\n",
            "\n",
            "train_loss_ave:\t0.101080\n",
            "test_loss_ave:\t0.190086\n",
            "test_accuracy: \t95.291139 %\n",
            "Epoch 9/99\n",
            "----------\n",
            "[50] running_loss: 0.087435\n",
            "[100] running_loss: 0.092977\n",
            "[150] running_loss: 0.073855\n",
            "[200] running_loss: 0.074198\n",
            "\n",
            "train_loss_ave:\t0.082529\n",
            "test_loss_ave:\t0.191358\n",
            "test_accuracy: \t95.569620 %\n",
            "Epoch 10/99\n",
            "----------\n",
            "[50] running_loss: 0.061567\n",
            "[100] running_loss: 0.076239\n",
            "[150] running_loss: 0.055362\n",
            "[200] running_loss: 0.063301\n",
            "\n",
            "train_loss_ave:\t0.064439\n",
            "test_loss_ave:\t0.184998\n",
            "test_accuracy: \t95.594937 %\n",
            "Epoch 11/99\n",
            "----------\n",
            "[50] running_loss: 0.069166\n",
            "[100] running_loss: 0.072582\n",
            "[150] running_loss: 0.064649\n",
            "[200] running_loss: 0.054194\n",
            "\n",
            "train_loss_ave:\t0.065475\n",
            "test_loss_ave:\t0.177214\n",
            "test_accuracy: \t95.924051 %\n",
            "Epoch 12/99\n",
            "----------\n",
            "[50] running_loss: 0.054308\n",
            "[100] running_loss: 0.057545\n",
            "[150] running_loss: 0.040913\n",
            "[200] running_loss: 0.066193\n",
            "\n",
            "train_loss_ave:\t0.055015\n",
            "test_loss_ave:\t0.171722\n",
            "test_accuracy: \t96.063291 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLqpjZPqYY-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "e3982ddf-08c5-45e3-83d4-18d0f1bfea89"
      },
      "source": [
        "net.eval()\n",
        "\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "  for (inputs, labels) in data_loaders['test']:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = net(inputs)\n",
        "    \n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    is_correct = (predicted == labels).squeeze()\n",
        "\n",
        "    for i in range(len(is_correct)):\n",
        "      label = labels[i]\n",
        "      class_correct[label] += is_correct[i].item()  # 正解なら1, 不正解なら0\n",
        "      class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "  print('Accuracy of %5s : %2.01f %%' % (\n",
        "    classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "  \n",
        "print('Accuracy Ave: %2.01f %%' % (100 * sum(class_correct) / sum(class_total)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of airplane : 96.5 %\n",
            "Accuracy of  bird : 95.5 %\n",
            "Accuracy of   car : 97.8 %\n",
            "Accuracy of   cat : 89.1 %\n",
            "Accuracy of  deer : 93.9 %\n",
            "Accuracy of   dog : 93.9 %\n",
            "Accuracy of horse : 94.1 %\n",
            "Accuracy of monkey : 96.4 %\n",
            "Accuracy of  ship : 98.0 %\n",
            "Accuracy of truck : 93.5 %\n",
            "Accuracy Ave: 94.9 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ursz_pLQmczS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "c858aa05-009a-4c28-ec92-8626368cae01"
      },
      "source": [
        "net.eval()\n",
        "\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "  for (inputs, labels) in data_loaders['train']:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = net(inputs)\n",
        "    \n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    is_correct = (predicted == labels).squeeze()\n",
        "\n",
        "    for i in range(len(is_correct)):\n",
        "      label = labels[i]\n",
        "      class_correct[label] += is_correct[i].item()  # 正解なら1, 不正解なら0\n",
        "      class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "  print('Accuracy of %5s : %2.01f %%' % (\n",
        "    classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "  \n",
        "print('Accuracy Ave: %2.01f %%' % (100 * sum(class_correct) / sum(class_total)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of airplane : 99.6 %\n",
            "Accuracy of  bird : 99.4 %\n",
            "Accuracy of   car : 99.8 %\n",
            "Accuracy of   cat : 98.0 %\n",
            "Accuracy of  deer : 99.4 %\n",
            "Accuracy of   dog : 99.6 %\n",
            "Accuracy of horse : 99.8 %\n",
            "Accuracy of monkey : 99.2 %\n",
            "Accuracy of  ship : 99.6 %\n",
            "Accuracy of truck : 99.6 %\n",
            "Accuracy Ave: 99.4 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukoJI9rpggwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 保存\n",
        "PATH = './drive/My Drive/wide_resnet'\n",
        "torch.save(net.state_dict(), PATH+'_gpu.pth')\n",
        "torch.save(net.to('cpu').state_dict(), PATH+'_cpu.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}